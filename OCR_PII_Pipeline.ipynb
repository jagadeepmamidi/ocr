{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR Pipeline Assignment - Handwritten Document PII Extraction\n",
    "\n",
    "**Objective:** Build a simple OCR + PII-extraction pipeline for handwritten documents in JPEG format.\n",
    "\n",
    "**Pipeline Flow:**\n",
    "```\n",
    "Input (handwritten JPEG) → Pre-processing → OCR → Text Cleaning → PII Detection → (Optional) Redacted Image\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment if running for the first time)\n",
    "# !pip install opencv-python easyocr numpy spacy\n",
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import easyocr\n",
    "import numpy as np\n",
    "import spacy\n",
    "import re\n",
    "import os\n",
    "from IPython.display import Image, display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"✓ All imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CONFIGURATION\n",
    "# ==========================================\n",
    "INPUT_FOLDER = \"inputs\"\n",
    "OUTPUT_FOLDER = \"outputs\"\n",
    "\n",
    "if not os.path.exists(OUTPUT_FOLDER):\n",
    "    os.makedirs(OUTPUT_FOLDER)\n",
    "    print(f\"✓ Created output folder: {OUTPUT_FOLDER}\")\n",
    "else:\n",
    "    print(f\"✓ Output folder exists: {OUTPUT_FOLDER}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Models\n",
    "\n",
    "Loading EasyOCR for text extraction and SpaCy for Named Entity Recognition (NER)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INIT] Loading EasyOCR...\")\n",
    "reader = easyocr.Reader(['en'], gpu=False) \n",
    "print(\"✓ EasyOCR loaded successfully\")\n",
    "\n",
    "print(\"\\n[INIT] Loading SpaCy...\")\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    print(\"✓ SpaCy loaded successfully\")\n",
    "except:\n",
    "    nlp = None\n",
    "    print(\"⚠ SpaCy model not found. Run: python -m spacy download en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. OCR Pipeline Class\n",
    "\n",
    "This class handles the complete pipeline:\n",
    "1. **Pre-processing**: Removes horizontal lines, enhances contrast\n",
    "2. **OCR**: Extracts text using EasyOCR\n",
    "3. **PII Detection**: Identifies sensitive information (names, emails, phones, dates)\n",
    "4. **Redaction**: Optionally blacks out PII in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProPipeline:\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        self.input_path = os.path.join(INPUT_FOLDER, filename)\n",
    "        self.image = cv2.imread(self.input_path)\n",
    "        \n",
    "        if self.image is None:\n",
    "            raise ValueError(f\"Could not load image: {self.input_path}\")\n",
    "            \n",
    "        self.processed_image = None\n",
    "        self.ocr_results = []\n",
    "        self.full_text = \"\"\n",
    "        self.pii_matches = [] \n",
    "\n",
    "    # -------------------------------------------------------------\n",
    "    # STAGE 1: INTELLIGENT PRE-PROCESSING\n",
    "    # -------------------------------------------------------------\n",
    "    def preprocess(self):\n",
    "        \"\"\"Remove horizontal lines and enhance text clarity\"\"\"\n",
    "        img = self.image.copy()\n",
    "\n",
    "        # 1. Convert to Grayscale\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # 2. Invert (Text becomes bright, background dark) - needed for line detection\n",
    "        gray_inv = cv2.bitwise_not(gray)\n",
    "\n",
    "        # 3. Detect Horizontal Lines\n",
    "        # We create a kernel shaped like a long horizontal line (e.g., 40x1 pixels)\n",
    "        horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (40, 1))\n",
    "        detected_lines = cv2.morphologyEx(gray_inv, cv2.MORPH_OPEN, horizontal_kernel)\n",
    "\n",
    "        # 4. Remove Lines (Subtract lines from the original inverted image)\n",
    "        # This keeps the text (vertical/curved strokes) but kills the horizontal lines\n",
    "        clean_inv = cv2.subtract(gray_inv, detected_lines)\n",
    "\n",
    "        # 5. Invert back to normal (Black text on White background)\n",
    "        clean = cv2.bitwise_not(clean_inv)\n",
    "\n",
    "        # 6. Enhance Contrast (CLAHE)\n",
    "        # This makes the faint ink darker and uniform\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        self.processed_image = clahe.apply(clean)\n",
    "\n",
    "        # Save the debug image so you can see if lines are gone\n",
    "        debug_path = os.path.join(OUTPUT_FOLDER, f\"debug_clean_{self.filename}\")\n",
    "        cv2.imwrite(debug_path, self.processed_image)\n",
    "        print(f\"   [DEBUG] Preprocessed image saved to {debug_path}\")\n",
    "\n",
    "        return self.processed_image\n",
    "\n",
    "    # -------------------------------------------------------------\n",
    "    # STAGE 2: OCR\n",
    "    # -------------------------------------------------------------\n",
    "    def run_ocr(self):\n",
    "        \"\"\"Extract text from preprocessed image using EasyOCR\"\"\"\n",
    "        print(f\"   [OCR] Scanning {self.filename}...\")\n",
    "        \n",
    "        # Use the CLEANED image now\n",
    "        results = reader.readtext(self.processed_image, detail=1, paragraph=False)\n",
    "        \n",
    "        self.ocr_results = results\n",
    "        self.full_text = \" \".join([res[1] for res in results])\n",
    "        return self.full_text\n",
    "\n",
    "    # -------------------------------------------------------------\n",
    "    # STAGE 3: PII DETECTION\n",
    "    # -------------------------------------------------------------\n",
    "    def detect_pii(self):\n",
    "        \"\"\"Detect PII using regex patterns and NLP\"\"\"\n",
    "        text = self.full_text\n",
    "        detected = []\n",
    "        \n",
    "        # Regex Patterns for common PII\n",
    "        patterns = {\n",
    "            'PHONE': r'(\\+91[\\-\\s]?)?[6-9]\\d{9}|\\d{3}[-\\.\\s]??\\d{3}[-\\.\\s]??\\d{4}',\n",
    "            'EMAIL': r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}',\n",
    "            'DATE': r'\\b\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4}\\b'\n",
    "        }\n",
    "\n",
    "        for p_type, pattern in patterns.items():\n",
    "            for match in re.finditer(pattern, text):\n",
    "                detected.append({'type': p_type, 'value': match.group()})\n",
    "\n",
    "        # NLP for Names, Organizations, Locations\n",
    "        if nlp:\n",
    "            doc = nlp(text)\n",
    "            for ent in doc.ents:\n",
    "                if ent.label_ in [\"PERSON\", \"ORG\", \"GPE\"]:\n",
    "                    if len(ent.text) > 2: \n",
    "                        detected.append({'type': ent.label_, 'value': ent.text})\n",
    "\n",
    "        self.pii_matches = detected\n",
    "        return detected\n",
    "\n",
    "    # -------------------------------------------------------------\n",
    "    # STAGE 4: REDACTION (Optional)\n",
    "    # -------------------------------------------------------------\n",
    "    def redact_image(self):\n",
    "        \"\"\"Black out detected PII in the original image\"\"\"\n",
    "        # We draw on the ORIGINAL image for the final result\n",
    "        redacted_img = self.image.copy()\n",
    "        \n",
    "        for (bbox, text, prob) in self.ocr_results:\n",
    "            is_sensitive = False\n",
    "            for pii in self.pii_matches:\n",
    "                clean_text = re.sub(r'[^\\w]', '', text).lower()\n",
    "                clean_pii = re.sub(r'[^\\w]', '', pii['value']).lower()\n",
    "                \n",
    "                if len(clean_text) > 2 and (clean_text in clean_pii or clean_pii in clean_text):\n",
    "                    is_sensitive = True\n",
    "                    break\n",
    "            \n",
    "            if is_sensitive:\n",
    "                (tl, tr, br, bl) = bbox\n",
    "                tl = (int(tl[0]), int(tl[1]))\n",
    "                br = (int(br[0]), int(br[1]))\n",
    "                cv2.rectangle(redacted_img, tl, br, (0, 0, 0), -1)\n",
    "        \n",
    "        return redacted_img\n",
    "\n",
    "    def save_results(self, final_image):\n",
    "        \"\"\"Save extracted text and redacted image\"\"\"\n",
    "        text_filename = os.path.join(OUTPUT_FOLDER, f\"extracted_{self.filename}.txt\")\n",
    "        with open(text_filename, \"w\", encoding='utf-8') as f:\n",
    "            f.write(self.full_text)\n",
    "            f.write(\"\\n\\n--- DETECTED PII ---\\n\")\n",
    "            for pii in self.pii_matches:\n",
    "                f.write(f\"{pii['type']}: {pii['value']}\\n\")\n",
    "        \n",
    "        img_filename = os.path.join(OUTPUT_FOLDER, f\"redacted_{self.filename}\")\n",
    "        cv2.imwrite(img_filename, final_image)\n",
    "        print(f\"   [DONE] Saved to {OUTPUT_FOLDER}\")\n",
    "        \n",
    "        return text_filename, img_filename\n",
    "\n",
    "print(\"✓ Pipeline class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run Pipeline on Test Documents\n",
    "\n",
    "Process all images in the `inputs` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all image files from input folder\n",
    "files = [f for f in os.listdir(INPUT_FOLDER) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "if not files:\n",
    "    print(f\"⚠ Please put images in '{INPUT_FOLDER}' folder\")\n",
    "else:\n",
    "    print(f\"Found {len(files)} image(s) to process\\n\")\n",
    "    \n",
    "    results_summary = []\n",
    "    \n",
    "    for file in files:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Processing: {file}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        try:\n",
    "            pipeline = ProPipeline(file)\n",
    "            \n",
    "            # Run the preprocessing\n",
    "            pipeline.preprocess()\n",
    "            \n",
    "            # Run OCR\n",
    "            text = pipeline.run_ocr()\n",
    "            print(f\"\\n   [EXTRACTED TEXT]\")\n",
    "            print(f\"   {text[:200]}...\") \n",
    "            \n",
    "            # Detect PII\n",
    "            pii = pipeline.detect_pii()\n",
    "            print(f\"\\n   [DETECTED PII] ({len(pii)} items)\")\n",
    "            for item in pii:\n",
    "                print(f\"   - {item['type']}: {item['value']}\")\n",
    "            \n",
    "            # Redact and save\n",
    "            final_img = pipeline.redact_image()\n",
    "            text_file, img_file = pipeline.save_results(final_img)\n",
    "            \n",
    "            results_summary.append({\n",
    "                'file': file,\n",
    "                'text_output': text_file,\n",
    "                'image_output': img_file,\n",
    "                'pii_count': len(pii)\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   [ERROR] {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "    \n",
    "    print(f\"\\n\\n{'='*60}\")\n",
    "    print(\"PROCESSING COMPLETE\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"\\nProcessed {len(results_summary)} file(s)\")\n",
    "    for result in results_summary:\n",
    "        print(f\"\\n{result['file']}:\")\n",
    "        print(f\"  - PII detected: {result['pii_count']}\")\n",
    "        print(f\"  - Text output: {result['text_output']}\")\n",
    "        print(f\"  - Redacted image: {result['image_output']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Results\n",
    "\n",
    "Display the original, preprocessed, and redacted images side by side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results for the first processed file\n",
    "if results_summary:\n",
    "    sample_file = results_summary[0]['file']\n",
    "    \n",
    "    # Load images\n",
    "    original = cv2.imread(os.path.join(INPUT_FOLDER, sample_file))\n",
    "    preprocessed = cv2.imread(os.path.join(OUTPUT_FOLDER, f\"debug_clean_{sample_file}\"))\n",
    "    redacted = cv2.imread(results_summary[0]['image_output'])\n",
    "    \n",
    "    # Convert BGR to RGB for matplotlib\n",
    "    original_rgb = cv2.cvtColor(original, cv2.COLOR_BGR2RGB)\n",
    "    redacted_rgb = cv2.cvtColor(redacted, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Create figure\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    axes[0].imshow(original_rgb)\n",
    "    axes[0].set_title('Original Image', fontsize=14, fontweight='bold')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(preprocessed, cmap='gray')\n",
    "    axes[1].set_title('Preprocessed (Lines Removed)', fontsize=14, fontweight='bold')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    axes[2].imshow(redacted_rgb)\n",
    "    axes[2].set_title('Redacted Image (PII Removed)', fontsize=14, fontweight='bold')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_FOLDER, 'results_comparison.png'), dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\n✓ Comparison saved to: {os.path.join(OUTPUT_FOLDER, 'results_comparison.png')}\")\n",
    "else:\n",
    "    print(\"No results to visualize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Display Extracted Text and PII\n",
    "\n",
    "Show the complete extracted text and all detected PII."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display extracted text for the first file\n",
    "if results_summary:\n",
    "    with open(results_summary[0]['text_output'], 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(f\"EXTRACTED TEXT FROM: {results_summary[0]['file']}\")\n",
    "    print(\"=\"*60)\n",
    "    print(content)\n",
    "else:\n",
    "    print(\"No text to display\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary and Next Steps\n",
    "\n",
    "### Pipeline Capabilities:\n",
    "- ✅ Handles slightly tilted images\n",
    "- ✅ Works with different handwriting styles\n",
    "- ✅ Processes basic doctor/clinic-style notes or forms\n",
    "- ✅ Removes horizontal lines that interfere with OCR\n",
    "- ✅ Detects PII: Names, Emails, Phone Numbers, Dates, Organizations, Locations\n",
    "- ✅ Optional redaction of sensitive information\n",
    "\n",
    "### Deliverables:\n",
    "1. ✅ **Python Notebook file** (this file)\n",
    "2. ✅ **Dependency document** (`requirements.txt`)\n",
    "3. ✅ **Results screenshot** (generated in outputs folder)\n",
    "4. ✅ **Ready for benchmarking** with additional documents\n",
    "\n",
    "### To test with new documents:\n",
    "1. Place your handwritten document images (JPEG/PNG) in the `inputs` folder\n",
    "2. Run cells 5-7 to process and visualize results\n",
    "3. Check the `outputs` folder for extracted text and redacted images"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
